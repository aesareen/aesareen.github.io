---
layout: post
title: "Project Two - Educationally Influenced: Predicting the Academic Success Rates of Students in Cyprus"
date: 2025-02-24 10:30:00-0400
description: "Trying to answer the old age question for teachers: What are the things that determine high-performing students and how can we see which students are more likely to be academically successful?"
tags: viz pandas linear-regression svm logistic-regression
categories: dtsc-3162
giscus_comments: false
related_posts: false
toc:
  beginning: true
---
# I. Introduction
As someone who always wanted to go into teaching, I have always been fascinated by the diverse makeups that classrooms bring together, there is perhaps not such a more heterogenous space in society that is so commonly available. The magic of teaching for me is that every single student carries their own dreams, aspirations, and motivations—and crucially from a pedagogical perspective, their own background knowledge. It is miraculously up the lecturer at hand to convey knowledge at a carefully-sculpted rate, depth, and breadth that sufficiently engages all students without leaving those behind that are clearly struggling with the ideas or stultifying those that clearly have sufficiently grasped the material and are ready for a greater challenge (or perhaps, most frustratingly for a teacher, students who simply do not care). In an ideal scenario, teachers could analyze the background and study habits of each student, develop a personalized plan that either curbs potential barricades to academic success or encourages characteristics that underpin in, and reap the success of a spirited, confident, and well-educated classroom.

Where such a ideality was previously limited to the imaginations of educators, like many things in the modern-day, it can increasingly become a reality with the rise of machine learning and artificial intelligence systems. Ethical considerations at bay (because they certainly are quite a few), the ability to input an entire student's demographics, personality, and interests into an algorithm and immediately how to best get that student to learn and critically, enjoy that learning, is maybe one of the most altruistic and revolutionary innovations brought upon this digital revolution.

Thus, the following project delves into a fundamental question: **Which features of a student are most correlated with academic success and how can we utilize these features to predict which grades they will achieve in their studies?**. Forecasting such an outcome takes more than just analyzing a student's study hours and class attendance; it demands at through look at their socioeconomic status, their familial circumstances, and their actions before, during, and after class. Only with such a holistic view can we even begin giving justice to this socially-essential inquiry.

### Where did this data even come from?
Courtesy of the amazing [UC Irvine Machine Learning Repository](https://www.archive.ics.uci.edu/) is a [dataset](https://archive.ics.uci.edu/dataset/856/higher+education+students+performance+evaluation) released in 2023 about Engineering and Educational Science students attending Near East University in Cyprus. The best part of this dataset is that was utilized to support findings in a paper named [*Student Performance Classification Using Artificial Intelligence Techniques*](https://link.springer.com/content/pdf/10.1007/978-3-030-35249-3.pdf), so while doing my analysis, I can compare the results to actual researchers that completed a very similar task (and see if I can beat them, probably not though). 

There are not an incredible amount of samples in the dataset (only 145), but quite a few features for each student that include: 
- Parental Education & Other Familial Information
- Study Habits (amount of hours, amount of scientific & non-scientific literature read, how often a student took notes in class)
- Attendance to various academic-related events and also classes
- Preparation before particular exams
- The student's academic performance (both in GPA and grade)

If you'd prefer to download this notebook, just press [here](https://github.com/aesareen/3162-portfolio/blob/main/assets/jupyter/project_2.ipynb).

# II. Pre-Processing and Visualizing the Data
We can load in our dataframe like always do to get started:

```python
edu_df: pd.DataFrame = pd.read_csv('./datasets/cyprus_education_dataset.csv')
```

Let's take a peek at our first ten rows:
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>STUDENT ID</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>...</th>
      <th>29</th>
      <th>30</th>
      <th>COURSE ID</th>
      <th>GRADE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>STUDENT1</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>STUDENT2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>...</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>STUDENT3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>STUDENT4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>141</th>
      <td>STUDENT142</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>5</td>
    </tr>
    <tr>
      <th>142</th>
      <td>STUDENT143</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>4</td>
      <td>3</td>
      <td>9</td>
      <td>1</td>
    </tr>
    <tr>
      <th>143</th>
      <td>STUDENT144</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <th>144</th>
      <td>STUDENT145</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>4</td>
      <td>9</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>145 rows × 33 columns (total)</p>
</div>

We can see that all of the column names and values are numerical, which is super helpful perhaps for a machine learning model but not so helpful for us mere human non-models. So, my first pre-processing step was simply renaming all the columns to the values they actually are so you (and I) can figure out what they are a little bit more. 

```python
# The columns are just numbers, so I am replacing them with their actual values
col_names: list = ['Age', 'Sex', 'School Type', 'Scholarship Percentage', 'Additional Work', 'Regular Art/Sports', 'Has Partner', 'Total Salary', 'Transportation Medium', 'Accommodation Type', "Mother's Education", "Father's Education", "Number of Sisters / Brothers", "Parental Status", "Mother's Occupation", "Father's Occupation", "Weekly Study Hours", "Reading frequency (non-scientific books/journals)", "Reading frequency (scientific books/journals)", "Attendance to department seminars / conferences", "Impact of projects / activities on your success", "Attendance to Classes", "Preparation to midterm exam 1", "Preparation to midterm exams 2", "Taking notes in classes", "Listening in classes", "Discussion improves my interest and success in the course", "Flip-classroom", "Cumulative GPA last semester", "Expected GPA at graduation", "Course ID", "Output Grade", "Student ID"]
edu_df.columns = col_names
```

Now we have:
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Sex</th>
      <th>School Type</th>
      <th>Scholarship Percentage</th>
      <th>...</th>
      <th>Expected GPA at graduation</th>
      <th>Course ID</th>
      <th>Output Grade</th>
      <th>Student ID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>STUDENT1</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>...</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>STUDENT2</td>
      <td>2</td>
      <td>2</td>
      <td>3</td>
      <td>...</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>STUDENT3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>...</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>STUDENT4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>3</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>141</th>
      <td>STUDENT142</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>5</td>
    </tr>
    <tr>
      <th>142</th>
      <td>STUDENT143</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>4</td>
      <td>3</td>
      <td>9</td>
      <td>1</td>
    </tr>
    <tr>
      <th>143</th>
      <td>STUDENT144</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>...</td>
      <td>5</td>
      <td>3</td>
      <td>9</td>
      <td>4</td>
    </tr>
    <tr>
      <th>144</th>
      <td>STUDENT145</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>...</td>
      <td>5</td>
      <td>4</td>
      <td>9</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>145 rows × 33 columns (total)</p>
</div>

Much better! Our values are still a bit vague (what is a 3 Scholarship Percentage), but we can modify each column as necessary for our visualization step. Now we can move on to seeing the first step actually pre-processing our data: verifying if there any null values. 

```python
print(f'The number of NaN values per column in our dataset: \n {edu_df.isna().sum().sort_values(ascending=False)}')
```

```
The number of NaN values per column in our dataset: 
 Age                       0
Sex                       0
School Type               0
Scholarship Percentage    0
Additional Work           0
Regular Art/Sports        0
Has Partner               0
Total Salary              0
Transportation Medium     0
Accommodation Type        0
dtype: int64
```

Ah! Perfect! Super unrealistic but UCI archive did actually tell us there are no missing values within this dataset, making it super easy to work with. That is likely the result of this being a very small and manually-collected collection process, so many missing values were likely handled long ago (also the fact that the original researchers would deal with them as part of their own ML work before releasing it to the public!). 

# III. Model Selection
For experimentation purposes, using a model that uses a linear decision boundary like logistic regression I think would be fun exercise to see an example of it failing quite badly at a particular dataset. What I am hoping to provide much better performance is a **Support Vector Machine with a non-linear kernel function**. This can be the perfect balance between simplicity but also dealing with the fact we are dealing with quite a bit of overlapping data that isn't linearly separable. 

# IV. Model Implementation
