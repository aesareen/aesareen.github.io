<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://aesareen.github.io/3162-portfolio/feed.xml" rel="self" type="application/atom+xml"/><link href="https://aesareen.github.io/3162-portfolio/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-11T03:39:54+00:00</updated><id>https://aesareen.github.io/3162-portfolio/feed.xml</id><title type="html">Arnav Sareen - Portfolio</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Project Two - Educationally Influenced: Predicting the Academic Success Rates of Students in Cyprus</title><link href="https://aesareen.github.io/3162-portfolio/blog/2025/project2/" rel="alternate" type="text/html" title="Project Two - Educationally Influenced: Predicting the Academic Success Rates of Students in Cyprus"/><published>2025-02-24T14:30:00+00:00</published><updated>2025-02-24T14:30:00+00:00</updated><id>https://aesareen.github.io/3162-portfolio/blog/2025/project2</id><content type="html" xml:base="https://aesareen.github.io/3162-portfolio/blog/2025/project2/"><![CDATA[<h1 id="i-introduction">I. Introduction</h1> <p>As someone who always wanted to go into teaching, I have always been fascinated by the diverse makeups that classrooms bring together, there is perhaps not such a more heterogenous space in society that is so commonly available. The magic of teaching for me is that every single student carries their own dreams, aspirations, and motivations—and crucially from a pedagogical perspective, their own background knowledge. It is miraculously up the lecturer at hand to convey knowledge at a carefully-sculpted rate, depth, and breadth that sufficiently engages all students without leaving those behind that are clearly struggling with the ideas or stultifying those that clearly have sufficiently grasped the material and are ready for a greater challenge (or perhaps, most frustratingly for a teacher, students who simply do not care). In an ideal scenario, teachers could analyze the background and study habits of each student, develop a personalized plan that either curbs potential barricades to academic success or encourages characteristics that underpin in, and reap the success of a spirited, confident, and well-educated classroom.</p> <p>Where such a ideality was previously limited to the imaginations of educators, like many things in the modern-day, it can increasingly become a reality with the rise of machine learning and artificial intelligence systems. Ethical considerations at bay (because they certainly are quite a few), the ability to input an entire student’s demographics, personality, and interests into an algorithm and immediately how to best get that student to learn and critically, enjoy that learning, is maybe one of the most altruistic and revolutionary innovations brought upon this digital revolution.</p> <p>Thus, the following project delves into a fundamental question: <strong>Which features of a student are most correlated with academic success and how can we utilize these features to predict which grades they will achieve in their studies?</strong>. Forecasting such an outcome takes more than just analyzing a student’s study hours and class attendance; it demands at through look at their socioeconomic status, their familial circumstances, and their actions before, during, and after class. Only with such a holistic view can we even begin giving justice to this socially-essential inquiry.</p> <h3 id="where-did-this-data-even-come-from">Where did this data even come from?</h3> <p>Courtesy of the amazing <a href="https://www.archive.ics.uci.edu/">UC Irvine Machine Learning Repository</a> is a <a href="https://archive.ics.uci.edu/dataset/856/higher+education+students+performance+evaluation">dataset</a> released in 2023 about Engineering and Educational Science students attending Near East University in Cyprus. The best part of this dataset is that was utilized to support findings in a paper named <a href="https://link.springer.com/content/pdf/10.1007/978-3-030-35249-3.pdf"><em>Student Performance Classification Using Artificial Intelligence Techniques</em></a>, so while doing my analysis, I can compare the results to actual researchers that completed a very similar task (and see if I can beat them, probably not though).</p> <p>There are not an incredible amount of samples in the dataset (only 145), but quite a few features for each student that include:</p> <ul> <li>Parental Education &amp; Other Familial Information</li> <li>Study Habits (amount of hours, amount of scientific &amp; non-scientific literature read, how often a student took notes in class)</li> <li>Attendance to various academic-related events and also classes</li> <li>Preparation before particular exams</li> <li>The student’s academic performance (both in GPA and grade)</li> </ul> <p>If you’d prefer to download this notebook, just press <a href="https://github.com/aesareen/3162-portfolio/blob/main/assets/jupyter/project_2.ipynb">here</a>.</p> <h1 id="ii-pre-processing-and-visualizing-the-data">II. Pre-Processing and Visualizing the Data</h1> <p>We can load in our dataframe like always do to get started:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">edu_df</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./datasets/cyprus_education_dataset.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Let’s take a peek at our first ten rows:</p> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>STUDENT ID</th> <th>1</th> <th>2</th> <th>3</th> <th>...</th> <th>29</th> <th>30</th> <th>COURSE ID</th> <th>GRADE</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>STUDENT1</td> <td>2</td> <td>2</td> <td>3</td> <td>...</td> <td>1</td> <td>1</td> <td>1</td> <td>1</td> </tr> <tr> <th>1</th> <td>STUDENT2</td> <td>2</td> <td>2</td> <td>3</td> <td>...</td> <td>2</td> <td>3</td> <td>1</td> <td>1</td> </tr> <tr> <th>2</th> <td>STUDENT3</td> <td>2</td> <td>2</td> <td>2</td> <td>...</td> <td>2</td> <td>2</td> <td>1</td> <td>1</td> </tr> <tr> <th>3</th> <td>STUDENT4</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>3</td> <td>2</td> <td>1</td> <td>1</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>141</th> <td>STUDENT142</td> <td>1</td> <td>1</td> <td>2</td> <td>...</td> <td>5</td> <td>3</td> <td>9</td> <td>5</td> </tr> <tr> <th>142</th> <td>STUDENT143</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>4</td> <td>3</td> <td>9</td> <td>1</td> </tr> <tr> <th>143</th> <td>STUDENT144</td> <td>2</td> <td>1</td> <td>2</td> <td>...</td> <td>5</td> <td>3</td> <td>9</td> <td>4</td> </tr> <tr> <th>144</th> <td>STUDENT145</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>5</td> <td>4</td> <td>9</td> <td>3</td> </tr> </tbody> </table> <p>145 rows × 33 columns (total)</p> </div> <p>We can see that all of the column names and values are numerical, which is super helpful perhaps for a machine learning model but not so helpful for us mere human non-models. So, my first pre-processing step was simply renaming all the columns to the values they actually are so you (and I) can figure out what they are a little bit more.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The columns are just numbers, so I am replacing them with their actual values
</span><span class="n">col_names</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Sex</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">School Type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Scholarship Percentage</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Additional Work</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Regular Art/Sports</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Has Partner</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Total Salary</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Transportation Medium</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Accommodation Type</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">Mother</span><span class="sh">'</span><span class="s">s Education</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Father</span><span class="sh">'</span><span class="s">s Education</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Number of Sisters / Brothers</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Parental Status</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Mother</span><span class="sh">'</span><span class="s">s Occupation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Father</span><span class="sh">'</span><span class="s">s Occupation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Weekly Study Hours</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Reading frequency (non-scientific books/journals)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Reading frequency (scientific books/journals)</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Attendance to department seminars / conferences</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Impact of projects / activities on your success</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Attendance to Classes</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Preparation to midterm exam 1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Preparation to midterm exams 2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Taking notes in classes</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Listening in classes</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Discussion improves my interest and success in the course</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Flip-classroom</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Cumulative GPA last semester</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Expected GPA at graduation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Course ID</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Output Grade</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Student ID</span><span class="sh">"</span><span class="p">]</span>
<span class="n">edu_df</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">col_names</span>
</code></pre></div></div> <p>Now we have:</p> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>Age</th> <th>Sex</th> <th>School Type</th> <th>Scholarship Percentage</th> <th>...</th> <th>Expected GPA at graduation</th> <th>Course ID</th> <th>Output Grade</th> <th>Student ID</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>STUDENT1</td> <td>2</td> <td>2</td> <td>3</td> <td>...</td> <td>1</td> <td>1</td> <td>1</td> <td>1</td> </tr> <tr> <th>1</th> <td>STUDENT2</td> <td>2</td> <td>2</td> <td>3</td> <td>...</td> <td>2</td> <td>3</td> <td>1</td> <td>1</td> </tr> <tr> <th>2</th> <td>STUDENT3</td> <td>2</td> <td>2</td> <td>2</td> <td>...</td> <td>2</td> <td>2</td> <td>1</td> <td>1</td> </tr> <tr> <th>3</th> <td>STUDENT4</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>3</td> <td>2</td> <td>1</td> <td>1</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> <td>...</td> </tr> <tr> <th>141</th> <td>STUDENT142</td> <td>1</td> <td>1</td> <td>2</td> <td>...</td> <td>5</td> <td>3</td> <td>9</td> <td>5</td> </tr> <tr> <th>142</th> <td>STUDENT143</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>4</td> <td>3</td> <td>9</td> <td>1</td> </tr> <tr> <th>143</th> <td>STUDENT144</td> <td>2</td> <td>1</td> <td>2</td> <td>...</td> <td>5</td> <td>3</td> <td>9</td> <td>4</td> </tr> <tr> <th>144</th> <td>STUDENT145</td> <td>1</td> <td>1</td> <td>1</td> <td>...</td> <td>5</td> <td>4</td> <td>9</td> <td>3</td> </tr> </tbody> </table> <p>145 rows × 33 columns (total)</p> </div> <p>Much better! Our values are still a bit vague (what is a 3 Scholarship Percentage), but we can modify each column as necessary for our visualization step. Now we can move on to seeing the first step actually pre-processing our data: verifying if there any null values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">The number of NaN values per column in our dataset: </span><span class="se">\n</span><span class="s"> </span><span class="si">{</span><span class="n">edu_df</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The number of NaN values per column in our dataset: 
 Age                       0
Sex                       0
School Type               0
Scholarship Percentage    0
Additional Work           0
Regular Art/Sports        0
Has Partner               0
Total Salary              0
Transportation Medium     0
Accommodation Type        0
dtype: int64
</code></pre></div></div> <p>Ah! Perfect! Super unrealistic but UCI archive did actually tell us there are no missing values within this dataset, making it super easy to work with. That is likely the result of this being a very small and manually-collected collection process, so many missing values were likely handled long ago (also the fact that the original researchers would deal with them as part of their own ML work before releasing it to the public!).</p> <p>However, we do not have zero pre-processing to do (ah, I wish). There is still quite a bit work we need to do if you want to make sense of all of this data and ensure that we are identifying the most pertinent features and the best model to identify trends within those features. If we are are trying to predict student outcomes, I think a good first step is to see what outcomes we are dealing with; in other words, model the distribution of grades and GPA that this particular dataset contains.</p> <p>However, in order to do that, we must do some interesting conversions as the grading system is currently numerically encoded and those numbers convert to the specific grading system used at NEU University in Cyprus, which must be further converted to ECTS grades and finally US-scale grades. To accomplish this, I used a resource provided by NEU to convert their grading system to ECTS and then utilized the most logical grade from the ECTS system based upon the equivalent US grade # Let’s change the grades so they are a lit bit more interpretable by us <a href="https://muhendislik.neu.edu.tr/wp-content/uploads/sites/146/2022/07/27/PGE_Exam-Regulations-Assessment-and-Grading.pdf?ver=01278343a7a9d5d38fc21f2487da1610">[1]</a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">grades_mapping</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="sh">'</span><span class="s">C-</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="sh">'</span><span class="s">C+</span><span class="sh">'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span> <span class="sh">'</span><span class="s">B-</span><span class="sh">'</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span> <span class="sh">'</span><span class="s">B+</span><span class="sh">'</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span> <span class="sh">'</span><span class="s">A-</span><span class="sh">'</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span> <span class="sh">'</span><span class="s">A+</span><span class="sh">'</span><span class="p">}</span>

<span class="c1"># Convert the numerical Cyprus grading system grades to American Letter Grades
</span><span class="n">edu_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Output Grade</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">edu_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Output Grade</span><span class="sh">'</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="n">grades_mapping</span><span class="p">)</span>

<span class="c1"># Make these letter grades ordinal
</span><span class="n">edu_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Output Grade</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Categorical</span><span class="p">(</span>
    <span class="n">edu_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Output Grade</span><span class="sh">'</span><span class="p">],</span> 
    <span class="n">categories</span><span class="o">=</span><span class="n">grades_mapping</span><span class="p">.</span><span class="nf">values</span><span class="p">(),</span> 
    <span class="n">ordered</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">edu_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Output Grade</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>From there, I used my favorite visualization package, <code class="language-plaintext highlighter-rouge">plotly</code> to make two graphs: One of the grade distribution of all the students within our training dataset and one of the expected GPA distribution of all the students.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/grade_dist_of_students-480.webp 480w,/3162-portfolio/assets/img/grade_dist_of_students-800.webp 800w,/3162-portfolio/assets/img/grade_dist_of_students-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/grade_dist_of_students.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/gpa_dist_of_students-480.webp 480w,/3162-portfolio/assets/img/gpa_dist_of_students-800.webp 800w,/3162-portfolio/assets/img/gpa_dist_of_students-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/gpa_dist_of_students.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Now, that might look a bit concerning given that most students do not have a very good grade, however, I view it as a potential benefit. It shows that there are a very select amount of students that are high-performing in this given survey and analyzing their patterns, situation, and demographics especially can provide a lot of insight into the background of successful students.</p> <p>Now, we need to get an idea of which features are particularly pertinent to student success. I have a few initial ideas (such as parent education, how often they attend classes, and how often they listen in classes), but I have no idea which factors high-performing students are doing the most. So I created a series of seaborn <em>swarmplots</em> to help me with this; swarmplots are the best pick here over a traditional scatterplot as much of the data we have overlaps with one another and we need to add a bit of jitter to fully see the data (which is especially helpful given we don’t have an overwhelming number of observations here, which swarmplots struggle with). We can apply some more pre-processing before using the swarmplot to make the axis titles make a bit more sense (previously, they were solely numerical values and I have no idea what a 3 in Mother’s Education means), and then make a subplot of each relevant feature against our target—a student’s grade—to visualize which features might be worth really analyzing!</p> <div class="row mt-3"> <div class="col-lg mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/education_feats_swarmplot-480.webp 480w,/3162-portfolio/assets/img/education_feats_swarmplot-800.webp 800w,/3162-portfolio/assets/img/education_feats_swarmplot-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/education_feats_swarmplot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h1 id="iii-model-selection">III. Model Selection</h1> <p>For experimentation purposes, using a model that uses a linear decision boundary like logistic regression I think would be fun exercise to see an example of it failing quite badly at a particular dataset. What I am hoping to provide much better performance is a <strong>Support Vector Machine with a non-linear kernel function</strong>. This can be the perfect balance between simplicity but also dealing with the fact we are dealing with quite a bit of overlapping data that isn’t linearly separable.</p> <h1 id="iv-model-implementation">IV. Model Implementation</h1> <h1 id="references">.References</h1>]]></content><author><name></name></author><category term="dtsc-3162"/><category term="viz"/><category term="pandas"/><category term="linear-regression"/><category term="svm"/><category term="logistic-regression"/><summary type="html"><![CDATA[Trying to answer the old age question for teachers: What are the things that determine high-performing students and how can we see which students are more likely to be academically successful?]]></summary></entry><entry><title type="html">Project One - Cities Rediscovering Themselves: The Aftermath of Local Law 18 in New York City’s Airbnb Market Across the Boroughs</title><link href="https://aesareen.github.io/3162-portfolio/blog/2025/project1/" rel="alternate" type="text/html" title="Project One - Cities Rediscovering Themselves: The Aftermath of Local Law 18 in New York City’s Airbnb Market Across the Boroughs"/><published>2025-01-30T14:30:00+00:00</published><updated>2025-01-30T14:30:00+00:00</updated><id>https://aesareen.github.io/3162-portfolio/blog/2025/project1</id><content type="html" xml:base="https://aesareen.github.io/3162-portfolio/blog/2025/project1/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>One of the defining features of housing throughout the 2010s was the rise of short-term homestay platforms such as Airbnb, Booking.com, and VRBO. Giving people the opportunity to temporarily rent out spaces in their house to travelers has spurred an industry in excess of $15 billion, with that figure only expected to nearly quadruple in the next decade <a href="https://www.businessresearchinsights.com/market-reports/homestay-platform-market-104124#:~:text=The%20global%20Homestay%20Platform%20Market%20size%20was,growing%20at%20a%20CAGR%20of%20about%2018.5%.&amp;text=The%20global%20COVID%2D19%20pandemic%20has%20been%20unprecedented,across%20all%20regions%20compared%20to%20pre%2Dpandemic%20levels">[1]</a>.</p> <p>With so many financial resources at stake, governments have taken proactive measures to maintain the stability of their housing markets and prevent the price gouging frequently associated with an influx of short-term homestays at the expense of viable, long-term housing for residents. No city has perhaps enacted for aggressive measures to achieve these ends than New York City, whose Local Law 18 requires all short-term renters (short-term here defined to any stay 30 days or less) to be registered with the city—prohibiting transactions from renters that do not comply—and any visits that fall below this threshold are required to have the host remain as an occupant alongside the visitor through the duration of their stay. The repercussions of such legislative actions have been profound, and there is already a wealth of research that demonstrates the effects of such laws have fundamentally altered the duration of stay makeup across the city and have funneled money away from individual-run homestay services to hotels run by massive conglomerations (the ethicality of this switch is up to the reader) <a href="https://www.airdna.co/blog/nycs-short-term-rental-crackdown">[2]</a>, <a href="https://skift.com/2024/09/01/banned-in-nyc-airbnb-1-year-later">[3]</a>.</p> <p>However, an in-depth look into a city removed more than a year from these changes has been much less prevalent. The characteristics of New York’s boroughs—The Bronx, Brooklyn, Manhattan, Queens, and Staten Island—and the vastly different socioeconomic, racial, and cultural values that are intrinsic to each open the question on <strong>who are bearing the cost of these changes the most and who remain largely unaffected?</strong> Furthermore, <strong>what is the current homestay market in each of the boroughs</strong>; what similarities tie the industry together and what differences factionalize it? To further clarify, the question that I hope to find out are the geographic spatially of Airbnb listings but also how different types of listings are distributed across the city. These are the questions, among others, that this project seeks to answer.</p> <h3 id="where-did-this-data-even-come-from">Where did this data even come from?</h3> <p>There is an awesome site called <a href="https://insideairbnb.com/">Inside AirBnb</a> that has Airbnb data for a wide variety of cities across the globe; this is where I accessed any data from February 2024 - November 2024. The 2023 dataset is unfortunately limited behind a paid data request, but luckily someone made it available on <a href="https://www.kaggle.com/datasets/godofoutcasts/new-york-city-airbnb-2023-public-data/data">Kaggle</a>, along with the <a href="https://www.kaggle.com/datasets/eddzzh/airbnb-nyccsv">2020 dataset</a> (yay!).</p> <p>The features of this dataset is extensive, and an entire <a href="https://docs.google.com/spreadsheets/d/1b_dvmyhb_kAJhUmv81rAxl4KcXn0Pymz/edit?gid=1967362979#gid=1967362979">data dictionary</a> delves into each attribute. However, both datasets include:</p> <ul> <li>The price of the AirBnb when the data was taken</li> <li>The neighborhood the AirBnb is located in</li> <li>The latitude and longtitude (approximate) of the hosting site</li> <li>The room type that is being offered</li> <li>The minimum and maximum nights a host can rent out</li> <li>The number of days the property is available for throughout the year</li> </ul> <p>The 2024 data has quite a few more features, such as the host acceptance rate, whether they are a superhost (own a variety of properties across the area), and detailed information about the property about the number of beds within the building and bathrooms. Some of this data can be a bit intrusive, such a host profile picture and description, however, I did not use this information within my analysis.</p> <p>If you’d prefer to download this notebook, just press <a href="https://github.com/aesareen/3162-portfolio/blob/main/assets/jupyter/project_1.ipynb">here</a>.</p> <h1 id="step-one-pre-processing-our-data">Step One: Pre-Processing our data!</h1> <p>Before we can do any sort of modeling, we have to load in our dependencies. Just for reference, here all the packages I utilized:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="kn">import</span> <span class="n">plotly.offline</span> <span class="k">as</span> <span class="n">pyo</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">plotly.graph_objects</span> <span class="k">as</span> <span class="n">go</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">pandas.api.types</span> <span class="kn">import</span> <span class="n">is_numeric_dtype</span>
<span class="kn">from</span> <span class="n">great_tables</span> <span class="kn">import</span> <span class="n">GT</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">html</span><span class="p">,</span> <span class="n">system_fonts</span><span class="p">,</span> <span class="n">style</span><span class="p">,</span> <span class="n">loc</span>
</code></pre></div></div> <p>Now we can load in our dataframes (in case you’re interested, you can find the files <a href="https://github.com/aesareen/3162-portfolio/blob/90a4d4d01069e2fb622d1cf82f0a6ae75bf4d63e/assets/jupyter/datasets/NYC-Airbnb-2023.csv">here for July 2023</a> and <a href="https://github.com/aesareen/3162-portfolio/blob/90a4d4d01069e2fb622d1cf82f0a6ae75bf4d63e/assets/jupyter/datasets/new_york_listings.csv">here for November 2024</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nov_listings</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./datasets/new_york_listings.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">jul_23_listings</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">./datasets/NYC-Airbnb-2023.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>We can take a peek at each table:</p> <h3 id="november-2024-data-nov_listings">November 2024 Data: <code class="language-plaintext highlighter-rouge">nov_listings</code></h3> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>id</th> <th>listing_url</th> <th>scrape_id</th> <th>last_scraped</th> <th>source</th> <th>name</th> <th>description</th> <th>neighborhood_overview</th> <th>picture_url</th> <th>host_id</th> <th>...</th> <th>review_scores_communication</th> <th>review_scores_location</th> <th>review_scores_value</th> <th>license</th> <th>instant_bookable</th> <th>calculated_host_listings_count</th> <th>calculated_host_listings_count_entire_homes</th> <th>calculated_host_listings_count_private_rooms</th> <th>calculated_host_listings_count_shared_rooms</th> <th>reviews_per_month</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>2595</td> <td>https://www.airbnb.com/rooms/2595</td> <td>20241104040953</td> <td>2024-11-04</td> <td>city scrape</td> <td>Skylit Midtown Castle Sanctuary</td> <td>Beautiful, spacious skylit studio in the heart...</td> <td>Centrally located in the heart of Manhattan ju...</td> <td>https://a0.muscache.com/pictures/miso/Hosting-...</td> <td>2845</td> <td>...</td> <td>4.8</td> <td>4.81</td> <td>4.40</td> <td>NaN</td> <td>f</td> <td>3</td> <td>3</td> <td>0</td> <td>0</td> <td>0.27</td> </tr> <tr> <th>1</th> <td>6848</td> <td>https://www.airbnb.com/rooms/6848</td> <td>20241104040953</td> <td>2024-11-04</td> <td>city scrape</td> <td>Only 2 stops to Manhattan studio</td> <td>Comfortable studio apartment with super comfor...</td> <td>NaN</td> <td>https://a0.muscache.com/pictures/e4f031a7-f146...</td> <td>15991</td> <td>...</td> <td>4.8</td> <td>4.69</td> <td>4.58</td> <td>NaN</td> <td>f</td> <td>1</td> <td>1</td> <td>0</td> <td>0</td> <td>1.04</td> </tr> <tr> <th>2</th> <td>6872</td> <td>https://www.airbnb.com/rooms/6872</td> <td>20241104040953</td> <td>2024-11-04</td> <td>city scrape</td> <td>Uptown Sanctuary w/ Private Bath (Month to Month)</td> <td>This charming distancing-friendly month-to-mon...</td> <td>This sweet Harlem sanctuary is a 10-20 minute ...</td> <td>https://a0.muscache.com/pictures/miso/Hosting-...</td> <td>16104</td> <td>...</td> <td>5.0</td> <td>5.00</td> <td>5.00</td> <td>NaN</td> <td>f</td> <td>2</td> <td>0</td> <td>2</td> <td>0</td> <td>0.03</td> </tr> </tbody> </table> <p>3 rows × 75 columns</p> </div> <h3 id="july-2023-data-jul_23_listings">July 2023 Data: <code class="language-plaintext highlighter-rouge">jul_23_listings</code></h3> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>id</th> <th>name</th> <th>host_id</th> <th>host_name</th> <th>neighbourhood_group</th> <th>neighbourhood</th> <th>latitude</th> <th>longitude</th> <th>room_type</th> <th>price</th> <th>minimum_nights</th> <th>number_of_reviews</th> <th>last_review</th> <th>reviews_per_month</th> <th>calculated_host_listings_count</th> <th>availability_365</th> <th>number_of_reviews_ltm</th> <th>license</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>2595</td> <td>Skylit Midtown Castle</td> <td>2845</td> <td>Jennifer</td> <td>Manhattan</td> <td>Midtown</td> <td>40.75356</td> <td>-73.98559</td> <td>Entire home/apt</td> <td>150</td> <td>30</td> <td>49</td> <td>2022-06-21</td> <td>0.30</td> <td>3</td> <td>314</td> <td>1</td> <td>NaN</td> </tr> <tr> <th>1</th> <td>5121</td> <td>BlissArtsSpace!</td> <td>7356</td> <td>Garon</td> <td>Brooklyn</td> <td>Bedford-Stuyvesant</td> <td>40.68535</td> <td>-73.95512</td> <td>Private room</td> <td>60</td> <td>30</td> <td>50</td> <td>2019-12-02</td> <td>0.30</td> <td>2</td> <td>365</td> <td>0</td> <td>NaN</td> </tr> <tr> <th>2</th> <td>5203</td> <td>Cozy Clean Guest Room - Family Apt</td> <td>7490</td> <td>MaryEllen</td> <td>Manhattan</td> <td>Upper West Side</td> <td>40.80380</td> <td>-73.96751</td> <td>Private room</td> <td>75</td> <td>2</td> <td>118</td> <td>2017-07-21</td> <td>0.72</td> <td>1</td> <td>0</td> <td>0</td> <td>NaN</td> </tr> </tbody> </table> <p>3 rows × 16 columns</p> </div> <p>Now with everything loaded, we can begin pre-processing our data. I start by removing some of the weird whitespace and capitalization that might be present throughout the file, along with removing the dollar sign from the price column (I do this for both datasets, but for brevity, I only show the code of <code class="language-plaintext highlighter-rouge">nov_listings</code>):</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nov_listings</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vectorize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">lower</span><span class="p">())(</span><span class="n">nov_listings</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>

<span class="n">nov_listings</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">nov_listings</span><span class="p">[</span><span class="sh">"</span><span class="s">price</span><span class="sh">"</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">$</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">,</span><span class="sh">''</span><span class="p">)</span> <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></div> <p>Then we can drop the columns we will definitely know we won’t use throughout the visualization and analysis process.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nov_listings</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">picture_url</span><span class="sh">'</span><span class="p">,</span> 
             <span class="sh">'</span><span class="s">host_url</span><span class="sh">'</span><span class="p">,</span>
             <span class="sh">'</span><span class="s">neighbourhood</span><span class="sh">'</span><span class="p">,</span> <span class="c1">#Not really the neighborhood 
</span>             <span class="sh">'</span><span class="s">host_thumbnail_url</span><span class="sh">'</span><span class="p">,</span> 
             <span class="sh">'</span><span class="s">host_picture_url</span><span class="sh">'</span><span class="p">,</span> 
             <span class="sh">'</span><span class="s">host_has_profile_pic</span><span class="sh">'</span><span class="p">,</span> 
             <span class="sh">'</span><span class="s">host_identity_verified</span><span class="sh">'</span><span class="p">,</span>
             <span class="sh">'</span><span class="s">license</span><span class="sh">'</span><span class="p">,</span>
             <span class="p">],</span>
    <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <p>Now we can begin moving some of the missing values if we need it. I start with a basic print statement to just see how bad it really is:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">The number of NaN values per column in nov_listings: </span><span class="se">\n</span><span class="s">
</span><span class="si">{</span><span class="n">nov_listings</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="si">:</span><span class="mi">11</span><span class="p">]</span><span class="si">}</span><span class="sh">'</span><span class="s">
    </span><span class="sh">"""</span>
    <span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"""</span><span class="s">
    </span><span class="sh">'</span><span class="s">The number of NaN values per column in jul_23_listings: </span><span class="se">\n</span><span class="s">
      </span><span class="si">{</span><span class="n">jul_23_listings</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="si">}</span><span class="s">
    </span><span class="sh">"""</span>
    <span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   The number of NaN values per column in nov_listings: 

    neighborhood_overview    16974
host_about               16224
host_response_time       15001
host_response_rate       15001
host_acceptance_rate     14983
last_review              11560
first_review             11560
host_location             7999
host_neighbourhood        7503
has_availability          5367
description               1044
dtype: int64'

    
    'The number of NaN values per column in jul_23_listings: 

      last_review                       10304
reviews_per_month                 10304
name                                 12
host_name                             5
neighbourhood_group                   0
neighbourhood                         0
id                                    0
host_id                               0
longitude                             0
latitude                              0
room_type                             0
price                                 0
number_of_reviews                     0
minimum_nights                        0
calculated_host_listings_count        0
availability_365                      0
dtype: int64
</code></pre></div></div> <p>As useful as raw values may be, they don’t do a lot in terms of telling us which columns we should target in large datasets, especially those with a large number of rows. So, I created a quick table that shows us the percentage of each column that is missing (and used the <code class="language-plaintext highlighter-rouge">great_tables</code> module to make it look nice because why not?).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/november_2024_nan_table-480.webp 480w,/3162-portfolio/assets/img/november_2024_nan_table-800.webp 800w,/3162-portfolio/assets/img/november_2024_nan_table-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/november_2024_nan_table.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/july_2023_nan_table-480.webp 480w,/3162-portfolio/assets/img/july_2023_nan_table-800.webp 800w,/3162-portfolio/assets/img/july_2023_nan_table-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/july_2023_nan_table.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>This creates an interesting dilemma; we can definitely drop <code class="language-plaintext highlighter-rouge">calendar_updated</code>, but what about the columns that have a noticeable proportion of their values missing? We can fill them in based upon the median, that is pretty easy, but I wanted to take a different approach given that I am taking a geography-centered point of view for this project: fill them based upon the median for that column within their borough. I think this can create a more accurate view without getting so specific that we are filling them based upon similar values in their neighborhood (which might have only a handful of values).</p> <p>To do that, I created a function that takes in a DataFrame, a column to find the median for, and a column to group the DataFrame by. The function then groups by the specified column, finds the median for that column, and then fills in all the missing values just as we discussed above. I then apply that to every column within all numeric columns that have at least 30% of their values missing.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">missing_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="p">(</span><span class="n">nov_listings</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">().</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">nov_listings</span><span class="p">.</span><span class="n">index</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">).</span><span class="nf">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">val</span> <span class="o">&gt;</span> <span class="p">.</span><span class="mi">3</span> <span class="ow">and</span> <span class="nf">is_numeric_dtype</span><span class="p">(</span><span class="n">nov_listings</span><span class="p">[</span><span class="n">name</span><span class="p">])]</span>

<span class="k">def</span> <span class="nf">fill_na_with_group_means</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">col</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">group_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">neighbourhood_group_cleansed</span><span class="sh">'</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s"> Returns a dictionary with the median for the grouped column that can be used to fill NaN values

    Args:
        df (pd.DataFrame): dataframe to utilize
        col (str): column to take the median of 
        group_col (str, optional): column to group by Defaults to </span><span class="sh">'</span><span class="s">neighbourhood_group_cleansed</span><span class="sh">'</span><span class="s">.

    Returns:
        pd.Series: series with the indexes as the grouped_by indexes and the values as the medians of each group for the specified column
    </span><span class="sh">"""</span>
    <span class="c1"># print(df.groupby(group_col)[col].transform('median'))
</span>    <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">].</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">group_col</span><span class="p">)[</span><span class="n">col</span><span class="p">].</span><span class="nf">transform</span><span class="p">(</span><span class="sh">'</span><span class="s">median</span><span class="sh">'</span><span class="p">))</span>

<span class="c1"># Do it for every missing column
</span><span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">missing_columns</span><span class="p">:</span>
    <span class="n">nov_listings</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="nf">fill_na_with_group_means</span><span class="p">(</span><span class="n">nov_listings</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>
</code></pre></div></div> <h1 id="step-two-visualizations">Step Two: Visualizations</h1> <p>Much of the code behind the visualizations are quite verbose, so I won’t include them in this post, but I will walk through my thought process for including each one.</p> <p>First, one of the major consequences of Local Law 18 was that it many thought that it significantly decrease the number of Airbnbs across the city, and based upon the visualization below, that certainly looks like the case.</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/listings_change-480.webp 480w,/3162-portfolio/assets/img/listings_change-800.webp 800w,/3162-portfolio/assets/img/listings_change-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/listings_change.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> While the city as a whole suffered from Airbnb decreases, the Bronx and Queens suffered the biggest causalities while the financially wealthy Manhattan withstood the worst of the legislation. </div> <p>To gain a better sense of how this spread looks through the city, you can explore the interactive maps below, with July on the left and November on the right (generated very easily through <code class="language-plaintext highlighter-rouge">plotly</code>!).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <div class="l-page"> <iframe src="/3162-portfolio/assets/plotly/jul_2023_airbnb_map.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed white;"></iframe> </div> </div> <div class="col-sm mt-3 mt-md-0"> <div class="l-page"> <iframe src="/3162-portfolio/assets/plotly/nov_2024_airbnb_map.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed white;"></iframe> </div> </div> </div> <p>That’s some pretty cool insight, and helps us answer one of our initial questions, <strong>what is the current homestay market in each borough</strong>. However, the number of boroughs doesn’t simply tell the entire story. How about their average prices? Let’s explore that!</p> <div class="row mt-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/avg_price_change-480.webp 480w,/3162-portfolio/assets/img/avg_price_change-800.webp 800w,/3162-portfolio/assets/img/avg_price_change-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/avg_price_change.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>That’s really interesting! We would believe that if listings have decreased, then the demand for homestays would have rapidly increased, thus driving up the prices. However, almost each borough experienced drops in their price, outside of the Bronx—which we know from our previous visualization experienced the worse of the listings drop.</p> <p>So that begs the question, why? Amid decreasing supply, why has the price dropped (which goes against the very basic economic principles I know)? Sure, we can maybe cite some external factors, such as a decrease in homestay demand or the shifting of consumers to hotels, but the latter seems unlikely given hotel prices actually skyrocketed following the implementation of the law <a href="https://shorttermrentalz.com/news/airbnb-new-york-city-urge-reversal-local-law-18/">[4]</a>.</p> <p>To be honest, I don’t know for sure, I am just a guy trying to complete his project for a class. But, I can make one last visualization that can maybe help us dissect the root cause behind this rather perplexing phenomenon. I used September 2020 Airbnb data (which I only utilized one column, so there wasn’t much data pre-processing really needed).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/sep_2020_host_age-480.webp 480w,/3162-portfolio/assets/img/sep_2020_host_age-800.webp 800w,/3162-portfolio/assets/img/sep_2020_host_age-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/sep_2020_host_age.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/3162-portfolio/assets/img/nov_host_age-480.webp 480w,/3162-portfolio/assets/img/nov_host_age-800.webp 800w,/3162-portfolio/assets/img/nov_host_age-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/3162-portfolio/assets/img/nov_host_age.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>So, we can see over the course of 4 years, the ages of each Airbnb in New York City drastically changed. In September 2020, the ages are skewed right, with a notable percentage of the houses being less than 5 years old. However, in 2024, we get a distribution that is much more symmetric (or even slightly left-skewed). So, the age compositions of Airbnbs over this time frame got much older. Why does that matter? Well a massive part of Local Law 18 was trying to prevent superhosts from snatching up much of the housing market and converting them into Airbnbs. We can maybe hypothesize when Local Law 18 was passed, these superhosts realized the commitment to maintain their properties is far too costly, thus leading them to abandon their enterprise. Thus, the options available were limited to those that actually lived in the city, which typically have more modest abodes—explaining the trend we saw in the previous chart!</p> <h1 id="conclusion">Conclusion</h1> <p>Regardless of the consequences we saw Local Law 18 cause across New York City, homestays are here to “stay” (please feel free to laugh); not just in New York but across the world. Thus, learning how these pieces of legislation are influencing one of the world’s largest metropolitan areas and provide an innumerable amount of guidance to countless other urban developments.</p>]]></content><author><name></name></author><category term="dtsc-3162"/><category term="viz"/><category term="pandas"/><category term="plotly"/><category term="pre-processing"/><summary type="html"><![CDATA[The biggest city in the world effectively banned short-term homestays. How did each borough react?]]></summary></entry></feed>